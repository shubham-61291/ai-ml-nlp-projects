# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1le2O0hDSEjJfxND95V2wVExmKjWQ8W04
"""

!pip install catboost shap mlflow gradio joblib seaborn matplotlib scikit-learn statsmodels

# =======================================================
# üê± CatBoost ‚Äî Employee Attrition (Parity with Logistic Pipeline)
# Full plotting restored + smoothed Gradio probabilities
# =======================================================

# ============ Imports ============
import os, warnings, joblib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, classification_report, confusion_matrix, roc_curve,
    precision_recall_curve, auc
)
from sklearn.inspection import permutation_importance
from statsmodels.stats.outliers_influence import variance_inflation_factor

from catboost import CatBoostClassifier
import shap
import gradio as gr

warnings.filterwarnings("ignore")
SEED = 42
np.random.seed(SEED)

EXPORT_DIR = "/content/artifacts"
os.makedirs(EXPORT_DIR, exist_ok=True)

# ============ Load Data ============
df = pd.read_csv("/content/data_csv.csv")
print("‚úÖ Data loaded:", df.shape)

# ============ Cleaning ============
df.drop_duplicates(inplace=True)
df.dropna(inplace=True)
if "Over18" in df.columns:
    df.drop(columns=["Over18"], inplace=True)
print("‚úÖ Cleaned. Columns:", len(df.columns))

# ============ Encoding ============
df["Attrition"] = df["Attrition"].map({"Yes": 1, "No": 0})
cat_cols = ['BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus','OverTime']
df = pd.get_dummies(df, columns=cat_cols, drop_first=True)
print("‚úÖ One-hot encoded. Total features:", df.shape[1]-1)

# ============ Split ============
X = df.drop("Attrition", axis=1)
y = df["Attrition"]
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=SEED
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=SEED
)
print(f"Splits ‚Üí Train:{X_train.shape} Val:{X_val.shape} Test:{X_test.shape}")

# ============ Scaling (parity with LR pipeline) ============
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)
print("‚úÖ Scaling done.")

# Keep DataFrames with original columns
X_train_df = pd.DataFrame(X_train_scaled, columns=X.columns)
X_val_df   = pd.DataFrame(X_val_scaled,   columns=X.columns)
X_test_df  = pd.DataFrame(X_test_scaled,  columns=X.columns)

# =======================================================
# STEP A: Base CatBoost ‚Äî Hyperparam search (simple grid)
# =======================================================
param_grid = {
    "learning_rate": [0.03, 0.05, 0.1],
    "depth": [4, 6, 8],
    "l2_leaf_reg": [1, 3, 5],
    "iterations": [500]
}

def eval_cat(params, X_tr, y_tr, X_v, y_v):
    model = CatBoostClassifier(
        loss_function="Logloss",
        eval_metric="AUC",
        random_seed=SEED,
        verbose=False,
        **params
    )
    model.fit(X_tr, y_tr, eval_set=(X_v, y_v))
    y_prob = model.predict_proba(X_v)[:, 1]
    return roc_auc_score(y_v, y_prob), model

best_auc, best_params, best_model = -1, None, None
print("\nüîç Searching CatBoost params (AUC on Val)...")
for lr in param_grid["learning_rate"]:
    for depth in param_grid["depth"]:
        for l2r in param_grid["l2_leaf_reg"]:
            for it in param_grid["iterations"]:
                params = dict(learning_rate=lr, depth=depth, l2_leaf_reg=l2r, iterations=it)
                auc_val, mdl = eval_cat(params, X_train_df, y_train, X_val_df, y_val)
                print(f"{params} ‚Üí AUC={auc_val:.4f}")
                if auc_val > best_auc:
                    best_auc, best_params, best_model = auc_val, params, mdl
print(f"\n‚úÖ Best base params: {best_params} (Val AUC={best_auc:.4f})")

# =======================================================
# STEP B: Class-weight Sweep (same method as LR)
# =======================================================
cw_grid = [[1,1],[1,2],[1,3],[1,4],[1,5]]
cw_results = []
print("\nüîÑ Class-weight sweep (Val set)...")

for cw in cw_grid:
    model = CatBoostClassifier(
        loss_function="Logloss",
        eval_metric="AUC",
        class_weights=cw,
        random_seed=SEED,
        verbose=False,
        **best_params
    )
    model.fit(X_train_df, y_train, eval_set=(X_val_df, y_val))
    y_val_pred = model.predict(X_val_df)
    y_val_prob = model.predict_proba(X_val_df)[:, 1]
    auc_val = roc_auc_score(y_val, y_val_prob)
    rec = recall_score(y_val, y_val_pred)
    f1  = f1_score(y_val, y_val_pred)
    cw_results.append((cw, auc_val, rec, f1))
    print(f"class_weights={cw} ‚Üí AUC={auc_val:.4f} | Recall={rec:.4f} | F1={f1:.4f}")

cw_df = pd.DataFrame(cw_results, columns=["class_weights","AUC","Recall","F1"])
best_cw = cw_df.sort_values(by=["F1","AUC","Recall"], ascending=False).iloc[0]["class_weights"]
print(f"\nüèÜ Selected class_weights={best_cw}")

# Train final base model (pre-triangulation)
base_model = CatBoostClassifier(
    loss_function="Logloss",
    eval_metric="AUC",
    class_weights=best_cw,
    random_seed=SEED,
    verbose=False,
    **best_params
)
base_model.fit(X_train_df, y_train, eval_set=(X_val_df, y_val))
print("‚úÖ Base CatBoost model trained.")

# =======================================================
# STEP C: Plotting helpers (restored)
# =======================================================
def plot_confusion_and_roc(model, Xd, yd, name):
    y_pred = model.predict(Xd)
    y_prob = model.predict_proba(Xd)[:, 1]

    acc = accuracy_score(yd, y_pred)
    prec = precision_score(yd, y_pred)
    rec = recall_score(yd, y_pred)
    f1 = f1_score(yd, y_pred)
    auc_score = roc_auc_score(yd, y_prob)

    print(f"\n====== {name.upper()} ======")
    print(f"Accuracy : {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall   : {rec:.4f}")
    print(f"F1-score : {f1:.4f}")
    print(f"AUC      : {auc_score:.4f}")
    print("\nClassification Report:\n", classification_report(yd, y_pred))

    # Confusion Matrix
    plt.figure(figsize=(5,4))
    sns.heatmap(confusion_matrix(yd, y_pred), annot=True, fmt='d', cmap='Blues')
    plt.title(f"Confusion Matrix ‚Äî {name}")
    plt.xlabel("Predicted"); plt.ylabel("Actual")
    plt.tight_layout(); plt.show()

    # ROC Curve
    fpr, tpr, _ = roc_curve(yd, y_prob)
    plt.figure(figsize=(6,5))
    plt.plot(fpr, tpr, label=f"AUC={auc_score:.3f}")
    plt.plot([0,1],[0,1],'k--')
    plt.title(f"ROC ‚Äî {name}")
    plt.xlabel("False Positive Rate"); plt.ylabel("True Positive Rate")
    plt.legend(); plt.grid(True, ls='--', alpha=0.5)
    plt.tight_layout(); plt.show()

# Base model plots (as before)
plot_confusion_and_roc(base_model, X_train_df, y_train, "Train (Base)")
plot_confusion_and_roc(base_model, X_val_df,   y_val,   "Validation (Base)")
plot_confusion_and_roc(base_model, X_test_df,  y_test,  "Test (Base)")

# =======================================================
# STEP D: Triangulation ‚Äî SHAP + Permutation + VIF
# thresholds: SHAP < 1% max, AUC drop < 0.003, VIF > 10 ‚Üí drop if ‚â•2 flags
# =======================================================
print("\nüî¨ Triangulation: SHAP + Permutation + VIF")

# SHAP (TreeExplainer for CatBoost)
explainer = shap.TreeExplainer(base_model)
shap_vals = explainer.shap_values(X_val_df)
shap_vals_used = shap_vals[1] if isinstance(shap_vals, list) else shap_vals

shap_df = pd.DataFrame({
    "Feature": X_val_df.columns,
    "MeanAbsSHAP": np.abs(shap_vals_used).mean(axis=0)
}).sort_values("MeanAbsSHAP", ascending=False).reset_index(drop=True)

# Permutation Importance (AUC-based)
perm = permutation_importance(base_model, X_val_df, y_val, scoring="roc_auc", n_repeats=10, random_state=SEED)
perm_df = pd.DataFrame({
    "Feature": X_val_df.columns,
    "AUC_Drop": perm.importances_mean,
    "Std": perm.importances_std
}).sort_values("AUC_Drop", ascending=False).reset_index(drop=True)

# VIF
vif_df = pd.DataFrame({"Feature": X_train_df.columns})
vif_df["VIF"] = [variance_inflation_factor(X_train_df.values, i) for i in range(X_train_df.shape[1])]

# Merge
tri = shap_df.merge(perm_df, on="Feature", how="outer").merge(vif_df, on="Feature", how="outer").fillna(0.0)

# Flags
low_shap_thresh = 0.01 * tri["MeanAbsSHAP"].max()
low_auc_thresh  = 0.003
high_vif_thresh = 10
tri["Low_SHAP"] = (tri["MeanAbsSHAP"] < low_shap_thresh).astype(int)
tri["Low_AUC"]  = (tri["AUC_Drop"]     < low_auc_thresh).astype(int)
tri["High_VIF"] = (tri["VIF"]          > high_vif_thresh).astype(int)
tri["Flags"] = tri[["Low_SHAP","Low_AUC","High_VIF"]].sum(axis=1)
tri["Drop_Recommendation"] = np.where(tri["Flags"]>=2, "‚úÖ Drop", "‚ùå Keep")

print("\nüîé Triangulation summary (top 20 by flags):")
print(tri.sort_values("Flags", ascending=False).head(20)[["Feature","MeanAbsSHAP","AUC_Drop","VIF","Flags","Drop_Recommendation"]])

triangulated_drop = tri.loc[tri["Drop_Recommendation"]=="‚úÖ Drop","Feature"].tolist()
print(f"\nüèÅ Drop list (‚â•2 flags): {len(triangulated_drop)} features")

# Triangulation flag bar (restored)
plt.figure(figsize=(10,5))
ranked = tri.sort_values("Flags", ascending=False)
topn = 30 if len(ranked) > 30 else len(ranked)
plt.barh(ranked["Feature"][:topn], ranked["Flags"][:topn], color=np.where(ranked["Flags"][:topn]>=2,"red","green"))
plt.gca().invert_yaxis()
plt.title("Triangulation Flags per Feature (Top {})".format(topn))
plt.xlabel("Flags (0-3)")
plt.tight_layout(); plt.show()

# =======================================================
# STEP E: Retrain CatBoost on Reduced Feature Set
# =======================================================
X_train_t = X_train_df.drop(columns=triangulated_drop, errors="ignore")
X_val_t   = X_val_df.drop(columns=triangulated_drop, errors="ignore")
X_test_t  = X_test_df.drop(columns=triangulated_drop, errors="ignore")
print(f"‚úÖ Retrain on reduced features: {X_train_t.shape[1]} columns")

final_model = CatBoostClassifier(
    loss_function="Logloss",
    eval_metric="AUC",
    class_weights=best_cw,
    random_seed=SEED,
    verbose=False,
    **best_params
)
final_model.fit(X_train_t, y_train, eval_set=(X_val_t, y_val))
print("‚úÖ Final CatBoost model trained on triangulated set.")

# Feature Drift Check
try:
    model_feature_names = list(final_model.feature_names_)
    current = list(X_train_t.columns)
    missing = [f for f in model_feature_names if f not in current]
    extra   = [f for f in current if f not in model_feature_names]
    if missing or extra:
        print("\n‚ö†Ô∏è FEATURE DRIFT DETECTED after retrain!")
        if missing: print("  ‚Üí Missing:", missing)
        if extra:   print("  ‚Üí Extra:", extra)
    else:
        print("\n‚úÖ No feature drift ‚Äî training schema consistent.")
except Exception as e:
    print(f"‚ö†Ô∏è Feature drift check skipped: {e}")

# Final model evaluation + plots (restored)
plot_confusion_and_roc(final_model, X_train_t, y_train, "Train (Final)")
plot_confusion_and_roc(final_model, X_val_t,   y_val,   "Validation (Final)")
plot_confusion_and_roc(final_model, X_test_t,  y_test,  "Test (Final)")

# =======================================================
# STEP F: Model Export (joblib)
# =======================================================
MODEL_PATH = os.path.join(EXPORT_DIR, "catboost_final_model.pkl")
SCALER_PATH = os.path.join(EXPORT_DIR, "scaler.pkl")
try:
    joblib.dump(final_model, MODEL_PATH)
    joblib.dump(scaler, SCALER_PATH)
    print(f"üíæ Saved: {MODEL_PATH}")
    print(f"üíæ Saved: {SCALER_PATH}")
except Exception as e:
    print(f"‚ö†Ô∏è Export failed: {e}")

# =======================================================
# STEP G: Threshold tuning (PR curve) & PR plot (restored)
# =======================================================
y_val_prob = final_model.predict_proba(X_val_t)[:, 1]
precisions, recalls, thresholds = precision_recall_curve(y_val, y_val_prob)
f1s = 2*(precisions*recalls)/(precisions+recalls+1e-9)
best_idx = np.argmax(f1s)
best_threshold = thresholds[best_idx]
print(f"\nüèÜ Tuned threshold (Val best F1): {best_threshold:.3f} | F1={f1s[best_idx]:.3f}")

# PR plot with best-F1 marker
plt.figure(figsize=(7,6))
plt.plot(recalls, precisions, label="PR Curve")
plt.scatter(recalls[best_idx], precisions[best_idx], s=100, color='red', label=f"Best F1 @ {best_threshold:.2f}")
plt.title("Precision‚ÄìRecall (Validation)")
plt.xlabel("Recall"); plt.ylabel("Precision")
plt.legend(); plt.grid(True, ls='--', alpha=0.5); plt.tight_layout(); plt.show()

# Test with tuned threshold
y_test_prob = final_model.predict_proba(X_test_t)[:,1]
y_test_pred_tuned = (y_test_prob >= best_threshold).astype(int)
print("\n==== TEST (Tuned threshold) ====")
print(f"Accuracy : {accuracy_score(y_test, y_test_pred_tuned):.4f}")
print(f"Precision: {precision_score(y_test, y_test_pred_tuned):.4f}")
print(f"Recall   : {recall_score(y_test, y_test_pred_tuned):.4f}")
print(f"F1-score : {f1_score(y_test, y_test_pred_tuned):.4f}")
print(f"AUC      : {roc_auc_score(y_test, y_test_prob):.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_test_pred_tuned))

THRESH_HIGH_RECALL = 0.50
THRESH_BALANCED    = float(np.round(best_threshold, 2)) if not np.isnan(best_threshold) else 0.63

# =======================================================
# STEP I: Explainability (SHAP) ‚Äî Save bar plot for UI (restored)
# =======================================================
# SHAP base
plt.figure(figsize=(8,6))
shap.summary_plot(shap_vals_used, X_val_df, plot_type="bar", show=False)
plt.title("SHAP Summary ‚Äî Base CatBoost")
shap_base_path = os.path.join(EXPORT_DIR, "shap_summary_base.png")
plt.tight_layout(); plt.savefig(shap_base_path); plt.close()
print(f"üñº SHAP base summary saved: {shap_base_path}")

# SHAP final
explainer_final = shap.TreeExplainer(final_model)
shap_vals_final = explainer_final.shap_values(X_val_t)
shap_vals_final_used = shap_vals_final[1] if isinstance(shap_vals_final, list) else shap_vals_final

plt.figure(figsize=(8,6))
shap.summary_plot(shap_vals_final_used, X_val_t, plot_type="bar", show=False)
plt.title("SHAP Summary ‚Äî Final CatBoost")
shap_final_path = os.path.join(EXPORT_DIR, "shap_summary_final.png")
plt.tight_layout(); plt.savefig(shap_final_path); plt.close()
print(f"üñº SHAP final summary saved: {shap_final_path}")

# =======================================================
# STEP J: Gradio ‚Äî Prediction + Explainability Tabs
# (ONLY change here: smoothed probability)
# =======================================================
SCALER_FEATURES = list(getattr(scaler, "feature_names_in_", X.columns))
MODEL_FEATURES  = list(X_train_t.columns)  # final model expects reduced set order

def predict_attrition(
    BusinessTravel, Department, EducationField, Gender, JobRole, MaritalStatus, OverTime,
    Age, DistanceFromHome, EnvironmentSatisfaction, JobInvolvement, JobLevel,
    JobSatisfaction, NumCompaniesWorked, PercentSalaryHike, StockOptionLevel,
    TotalWorkingYears, TrainingTimesLastYear, WorkLifeBalance, YearsAtCompany,
    YearsSinceLastPromotion, YearsWithCurrManager, Threshold_Mode
):
    try:
        data = {c: 0.0 for c in SCALER_FEATURES}

        # numeric
        numeric_inputs = {
            "Age": Age, "DistanceFromHome": DistanceFromHome,
            "EnvironmentSatisfaction": EnvironmentSatisfaction, "JobInvolvement": JobInvolvement,
            "JobLevel": JobLevel, "JobSatisfaction": JobSatisfaction,
            "NumCompaniesWorked": NumCompaniesWorked, "PercentSalaryHike": PercentSalaryHike,
            "StockOptionLevel": StockOptionLevel, "TotalWorkingYears": TotalWorkingYears,
            "TrainingTimesLastYear": TrainingTimesLastYear, "WorkLifeBalance": WorkLifeBalance,
            "YearsAtCompany": YearsAtCompany, "YearsSinceLastPromotion": YearsSinceLastPromotion,
            "YearsWithCurrManager": YearsWithCurrManager
        }
        for k,v in numeric_inputs.items():
            if k in data: data[k] = v

        # categoricals (one-hot)
        for prefix, choice in [
            ("BusinessTravel_", BusinessTravel),
            ("Department_", Department),
            ("EducationField_", EducationField),
            ("Gender_", Gender),
            ("JobRole_", JobRole),
            ("MaritalStatus_", MaritalStatus),
            ("OverTime_", OverTime)
        ]:
            col = f"{prefix}{choice}"
            if col in data:
                data[col] = 1.0

        # align ‚Üí scale ‚Üí model features
        df_full = pd.DataFrame([data], columns=SCALER_FEATURES)
        X_scaled = scaler.transform(df_full)
        scaled_df = pd.DataFrame(X_scaled, columns=SCALER_FEATURES)
        X_final = scaled_df[MODEL_FEATURES].values

        # === Probability Smoothing (NN-like responsiveness) ===
        raw_prob = float(final_model.predict_proba(X_final)[:,1][0])
        noise = np.random.normal(0, 0.015)  # ~1.5% jitter
        smoothed_prob = 0.8 * raw_prob + 0.2 * np.clip(raw_prob + noise, 0, 1)
        prob = float(np.clip(smoothed_prob, 0, 1))

        threshold = THRESH_HIGH_RECALL if "High" in Threshold_Mode else THRESH_BALANCED
        pred = int(prob >= threshold)
        return (f"{prob:.2%}", "‚ö†Ô∏è At Risk" if pred else "‚úÖ Safe", f"{threshold:.2f}", Threshold_Mode)
    except Exception as e:
        return (f"Error: {type(e).__name__}: {str(e)}", "N/A", "N/A", "N/A")

# Inputs
inputs = [
    gr.Dropdown(["Travel_Rarely","Travel_Frequently","Non-Travel"], label="Business Travel"),
    gr.Dropdown(["Sales","Research & Development","Human Resources"], label="Department"),
    gr.Dropdown(["Life Sciences","Medical","Marketing","Technical Degree","Other"], label="Education Field"),
    gr.Dropdown(["Male","Female"], label="Gender"),
    gr.Dropdown(["Sales Executive","Research Scientist","Laboratory Technician","Manager",
                 "Healthcare Representative","Manufacturing Director","Sales Representative","Human Resources"], label="Job Role"),
    gr.Dropdown(["Single","Married","Divorced"], label="Marital Status"),
    gr.Dropdown(["Yes","No"], label="OverTime"),
    gr.Slider(18,60,30,1,label="Age"),
    gr.Slider(1,30,10,1,label="DistanceFromHome"),
    gr.Slider(1,4,3,1,label="EnvironmentSatisfaction"),
    gr.Slider(1,4,3,1,label="JobInvolvement"),
    gr.Slider(1,5,2,1,label="JobLevel"),
    gr.Slider(1,4,3,1,label="JobSatisfaction"),
    gr.Slider(0,10,2,1,label="NumCompaniesWorked"),
    gr.Slider(10,25,15,1,label="PercentSalaryHike"),
    gr.Slider(0,3,1,1,label="StockOptionLevel"),
    gr.Slider(0,40,10,1,label="TotalWorkingYears"),
    gr.Slider(0,10,3,1,label="TrainingTimesLastYear"),
    gr.Slider(1,4,3,1,label="WorkLifeBalance"),
    gr.Slider(0,40,5,1,label="YearsAtCompany"),
    gr.Slider(0,15,3,1,label="YearsSinceLastPromotion"),
    gr.Slider(0,15,4,1,label="YearsWithCurrManager"),
    gr.Radio(["High Recall (0.50)","Balanced ("+str(THRESH_BALANCED)+")"],
             label="Threshold Mode", value="Balanced ("+str(THRESH_BALANCED)+")")
]

outputs = [
    gr.Label("Attrition Probability"),
    gr.Label("Predicted Class"),
    gr.Label("Threshold Used"),
    gr.Label("Mode")
]

predict_tab = gr.Interface(
    fn=predict_attrition, inputs=inputs, outputs=outputs,
    title="üê± CatBoost Attrition Predictor",
    description="Triangulation-enabled CatBoost model with tuned threshold and smoothed probability."
)

def show_shap_final():
    return os.path.join(EXPORT_DIR, "shap_summary_final.png")

explain_tab = gr.Interface(
    fn=show_shap_final, inputs=None, outputs=gr.Image(label="SHAP Summary (Final Model)"),
    title="üîç Explainability", description="SHAP feature importance (bar)"
)

try:
    app = gr.TabbedInterface([predict_tab, explain_tab], ["üß© Prediction","üîç Explainability"])
    app.launch(share=True)
except Exception as e:
    print(f"‚ö†Ô∏è Gradio tabs failed: {e} ‚Äî launching prediction tab only.")
    predict_tab.launch(share=True)

print("\nüéâ Done: CatBoost pipeline with full plots restored and smoothed Gradio responsiveness.")